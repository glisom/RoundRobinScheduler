diff -Naur orig/linux-2.6.32.60//arch/x86/include/asm/unistd_32.h kernel/linux-2.6.32.60//arch/x86/include/asm/unistd_32.h
--- orig/linux-2.6.32.60//arch/x86/include/asm/unistd_32.h	2013-03-21 00:34:57.000000000 -0500
+++ kernel/linux-2.6.32.60//arch/x86/include/asm/unistd_32.h	2015-04-26 13:07:03.000000000 -0500
@@ -343,6 +343,7 @@
 #define __NR_rt_tgsigqueueinfo	335
 #define __NR_perf_event_open	336
 #define __NR_sched_other_rr_getquantum	337
+#define __NR_sched_other_rr_setquantum  338
 
 #ifdef __KERNEL__
 
diff -Naur orig/linux-2.6.32.60//arch/x86/kernel/syscall_table_32.S kernel/linux-2.6.32.60//arch/x86/kernel/syscall_table_32.S
--- orig/linux-2.6.32.60//arch/x86/kernel/syscall_table_32.S	2013-03-21 00:34:57.000000000 -0500
+++ kernel/linux-2.6.32.60//arch/x86/kernel/syscall_table_32.S	2015-04-26 13:05:56.000000000 -0500
@@ -337,3 +337,4 @@
 	.long sys_rt_tgsigqueueinfo	/* 335 */
 	.long sys_perf_event_open
 	.long sys_sched_other_rr_getquantum
+  .long sys_sched_other_rr_setquantum
diff -Naur orig/linux-2.6.32.60//include/linux/syscalls.h kernel/linux-2.6.32.60//include/linux/syscalls.h
--- orig/linux-2.6.32.60//include/linux/syscalls.h	2013-03-21 16:29:12.000000000 -0500
+++ kernel/linux-2.6.32.60//include/linux/syscalls.h	2015-04-26 13:07:37.000000000 -0500
@@ -887,4 +887,5 @@
 			unsigned long fd, unsigned long pgoff);
 
 asmlinkage long sys_sched_other_rr_getquantum(void);
+asmlinkage long sys_sched_other_rr_setquantum(unsigned int);
 #endif
diff -Naur orig/linux-2.6.32.60//kernel/sched.c kernel/linux-2.6.32.60//kernel/sched.c
--- orig/linux-2.6.32.60//kernel/sched.c	2013-03-21 17:33:12.000000000 -0500
+++ kernel/linux-2.6.32.60//kernel/sched.c	2015-04-26 13:23:42.000000000 -0500
@@ -1925,6 +1925,7 @@
 # include "sched_debug.c"
 #endif
 
+
 #define sched_class_highest (&rt_sched_class)
 #define for_each_class(class) \
 	for (class = sched_class_highest; class; class = class->next)
@@ -6501,6 +6502,10 @@
 		p->sched_class = &fair_sched_class;
 		break;
 	case SCHED_FIFO:
+  case SCHED_OTHER_RR:
+    printk("SELECTED SCHED_OTHER_RR\n");
+    p->sched_class = &other_rr_sched_class;
+    break;
 	case SCHED_RR:
 		p->sched_class = &rt_sched_class;
 		break;
@@ -6552,10 +6557,10 @@
 
 		if (policy != SCHED_FIFO && policy != SCHED_RR &&
 		policy != SCHED_NORMAL && policy != SCHED_BATCH &&
-		policy != SCHED_IDLE)
+		policy != SCHED_IDLE && policy != SCHED_OTHER_RR)
 			return -EINVAL;
 	}
-
+  
 	/*
 	 * Valid priorities for SCHED_FIFO and SCHED_RR are
 	 * 1..MAX_USER_RT_PRIO-1, valid priority for SCHED_NORMAL,
@@ -7216,6 +7221,12 @@
 	return other_rr_time_slice;
 }
 
+SYSCALL_DEFINE1(sched_other_rr_setquantum, unsigned int, quantum) {
+  other_rr_time_slice = quantum;
+  printk("QUANTUM HAS BEEN CHANGED TO %d\n", quantum);
+  return 0;
+}
+
 static const char stat_nam[] = TASK_STATE_TO_CHAR_STR;
 
 void sched_show_task(struct task_struct *p)
diff -Naur orig/linux-2.6.32.60//kernel/sched_other_rr.c kernel/linux-2.6.32.60//kernel/sched_other_rr.c
--- orig/linux-2.6.32.60//kernel/sched_other_rr.c	2013-03-21 16:29:12.000000000 -0500
+++ kernel/linux-2.6.32.60//kernel/sched_other_rr.c	2015-04-26 13:23:51.000000000 -0500
@@ -9,21 +9,21 @@
  */
 static void update_curr_other_rr(struct rq *rq)
 {
-	struct task_struct *curr = rq->curr;
-	u64 delta_exec;
+    struct task_struct *curr = rq->curr;
+    u64 delta_exec;
 
-	if (!task_has_other_rr_policy(curr))
-		return;
+    if (!task_has_other_rr_policy(curr))
+        return;
 
-	delta_exec = rq->clock - curr->se.exec_start;
-	if (unlikely((s64)delta_exec < 0))
-		delta_exec = 0;
+    delta_exec = rq->clock - curr->se.exec_start;
+    if (unlikely((s64)delta_exec < 0))
+        delta_exec = 0;
 
-	schedstat_set(curr->se.exec_max, max(curr->se.exec_max, delta_exec));
+    schedstat_set(curr->se.exec_max, max(curr->se.exec_max, delta_exec));
 
-	curr->se.sum_exec_runtime += delta_exec;
-	curr->se.exec_start = rq->clock;
-	cpuacct_charge(curr, delta_exec);
+    curr->se.sum_exec_runtime += delta_exec;
+    curr->se.exec_start = rq->clock;
+    cpuacct_charge(curr, delta_exec);
 }
 
 /*
@@ -31,15 +31,19 @@
  */
 static void enqueue_task_other_rr(struct rq *rq, struct task_struct *p, int wakeup, bool b)
 {
-	// not yet implemented
+    update_curr_other_rr(rq);
+    // add task to list tail, increment number of running tasks
+    list_add_tail(&p->other_rr_run_list, &rq->other_rr.queue);
+    rq->other_rr.nr_running++;
 }
 
 static void dequeue_task_other_rr(struct rq *rq, struct task_struct *p, int sleep)
 {
-	// first update the task's runtime statistics
-	update_curr_other_rr(rq);
-
-	// not yet implemented
+    // first update the task's runtime statistics
+    update_curr_other_rr(rq);
+    // remove task from head, decrement number of running tasks
+    list_del(&p->other_rr_run_list);
+    rq->other_rr.nr_running--;
 }
 
 /*
@@ -48,16 +52,15 @@
  */
 static void requeue_task_other_rr(struct rq *rq, struct task_struct *p)
 {
-	list_move_tail(&p->other_rr_run_list, &rq->other_rr.queue);
+    list_move_tail(&p->other_rr_run_list, &rq->other_rr.queue);
 }
 
 /*
  * current process is relinquishing control of the CPU
  */
-static void
-yield_task_other_rr(struct rq *rq)
+static void yield_task_other_rr(struct rq *rq)
 {
-	// not yet implemented
+    requeue_task_other_rr(rq, &rq->curr);
 }
 
 /*
@@ -73,26 +76,31 @@
  */
 static struct task_struct *pick_next_task_other_rr(struct rq *rq)
 {
-	struct task_struct *next;
-	struct list_head *queue;
-	struct other_rr_rq *other_rr_rq;
-
-	// not yet implemented
-
-	/* after selecting a task, we need to set a timer to maintain correct
-	 * runtime statistics. You can uncomment this line after you have
-	 * written the code to select the appropriate task.
-	 */
-	//next->se.exec_start = rq->clock;
-	
-	/* you need to return the selected task here */
-	return NULL;
+    struct task_struct *next;
+    struct list_head *queue = &rq->other_rr.queue;
+
+    // check if the task queue is empty, finish if so
+    if (list_empty(queue)) {
+        next = NULL;
+    }
+    // else get the next task, update its start statistic
+    else {
+        next = list_first_entry(queue, struct task_struct, other_rr_run_list);
+
+        /* after selecting a task, we need to set a timer to maintain correct
+         * runtime statistics. You can uncomment this line after you have
+         * written the code to select the appropriate task.
+         */
+        next->se.exec_start = rq->clock;
+    }
+    /* you need to return the selected task here */
+    return next;
 }
 
 static void put_prev_task_other_rr(struct rq *rq, struct task_struct *p)
 {
-	update_curr_other_rr(rq);
-	p->se.exec_start = 0;
+    update_curr_other_rr(rq);
+    p->se.exec_start = 0;
 }
 
 #ifdef CONFIG_SMP
@@ -105,69 +113,68 @@
  */
 static struct task_struct *load_balance_start_other_rr(void *arg)
 {
-	struct rq *rq = arg;
-	struct list_head *head, *curr;
-	struct task_struct *p;
+    struct rq *rq = arg;
+    struct list_head *head, *curr;
+    struct task_struct *p;
 
-	head = &rq->other_rr.queue;
-	curr = head->prev;
+    head = &rq->other_rr.queue;
+    curr = head->prev;
 
-	p = list_entry(curr, struct task_struct, other_rr_run_list);
+    p = list_entry(curr, struct task_struct, other_rr_run_list);
 
-	curr = curr->prev;
+    curr = curr->prev;
 
-	rq->other_rr.other_rr_load_balance_head = head;
-	rq->other_rr.other_rr_load_balance_curr = curr;
+    rq->other_rr.other_rr_load_balance_head = head;
+    rq->other_rr.other_rr_load_balance_curr = curr;
 
-	return p;
+    return p;
 }
 
 static struct task_struct *load_balance_next_other_rr(void *arg)
 {
-	struct rq *rq = arg;
-	struct list_head *curr;
-	struct task_struct *p;
+    struct rq *rq = arg;
+    struct list_head *curr;
+    struct task_struct *p;
 
-	curr = rq->other_rr.other_rr_load_balance_curr;
+    curr = rq->other_rr.other_rr_load_balance_curr;
 
-	p = list_entry(curr, struct task_struct, other_rr_run_list);
-	curr = curr->prev;
-	rq->other_rr.other_rr_load_balance_curr = curr;
+    p = list_entry(curr, struct task_struct, other_rr_run_list);
+    curr = curr->prev;
+    rq->other_rr.other_rr_load_balance_curr = curr;
 
-	return p;
+    return p;
 }
 
-static unsigned long
-load_balance_other_rr(struct rq *this_rq, int this_cpu, struct rq *busiest,
-		unsigned long max_load_move,
-		struct sched_domain *sd, enum cpu_idle_type idle,
-		int *all_pinned, int *this_best_prio)
+static unsigned long load_balance_other_rr(struct rq *this_rq, int this_cpu, struct rq *busiest,
+        unsigned long max_load_move,
+        struct sched_domain *sd, enum cpu_idle_type idle,
+        int *all_pinned, int *this_best_prio)
 {
-	struct rq_iterator other_rr_rq_iterator;
+    struct rq_iterator other_rr_rq_iterator;
 
-	other_rr_rq_iterator.start = load_balance_start_other_rr;
-	other_rr_rq_iterator.next = load_balance_next_other_rr;
-	/* pass 'busiest' rq argument into
-	 * load_balance_[start|next]_other_rr iterators
-	 */
-	other_rr_rq_iterator.arg = busiest;
+    other_rr_rq_iterator.start = load_balance_start_other_rr;
+    other_rr_rq_iterator.next = load_balance_next_other_rr;
+    /* pass 'busiest' rq argument into
+     * load_balance_[start|next]_other_rr iterators
+     */
+    other_rr_rq_iterator.arg = busiest;
 
-	return balance_tasks(this_rq, this_cpu, busiest, max_load_move, sd,
-			     idle, all_pinned, this_best_prio, &other_rr_rq_iterator);
+    return balance_tasks(this_rq, this_cpu, busiest, max_load_move, sd,
+            idle, all_pinned, this_best_prio, &other_rr_rq_iterator);
 }
 
-static int
+    static int
 move_one_task_other_rr(struct rq *this_rq, int this_cpu, struct rq *busiest,
-		 struct sched_domain *sd, enum cpu_idle_type idle)
+        struct sched_domain *sd, enum cpu_idle_type idle)
 {
-	struct rq_iterator other_rr_rq_iterator;
+    struct rq_iterator other_rr_rq_iterator;
 
-	other_rr_rq_iterator.start = load_balance_start_other_rr;
-	other_rr_rq_iterator.next = load_balance_next_other_rr;
-	other_rr_rq_iterator.arg = busiest;
+    other_rr_rq_iterator.start = load_balance_start_other_rr;
+    other_rr_rq_iterator.next = load_balance_next_other_rr;
+    other_rr_rq_iterator.arg = busiest;
 
-	return iter_move_one_task(this_rq, this_cpu, busiest, sd, idle,
-				  &other_rr_rq_iterator);
+    return iter_move_one_task(this_rq, this_cpu, busiest, sd, idle,
+            &other_rr_rq_iterator);
 }
 #endif
 
@@ -176,10 +183,26 @@
  */
 static void task_tick_other_rr(struct rq *rq, struct task_struct *p,int queued)
 {
-	// first update the task's runtime statistics
-	update_curr_other_rr(rq);
+    // first update the task's runtime statistics
+    update_curr_other_rr(rq);
 
-	// not yet implemented
+    // check if quantum is 0, if so, always proceed with the task until it is
+    // finished
+    if (other_rr_time_slice == 0) {
+        return;
+    }
+    // else check if the slice is 0, if so queue the next task
+    else {
+        if (p->task_time_slice == 0) {
+            p->task_time_slice = other_rr_time_slice;
+            set_tsk_need_resched(p);
+            requeue_task_other_rr(rq, p);
+        }
+        // else decrement the time slice
+        else {
+            p->task_time_slice--;
+        }
+    } 
 }
 
 /*
@@ -188,54 +211,54 @@
  */
 static void set_curr_task_other_rr(struct rq *rq)
 {
-	struct task_struct *p = rq->curr;
-	p->se.exec_start = rq->clock;
+    struct task_struct *p = rq->curr;
+    p->se.exec_start = rq->clock;
 }
 
 /*
  * We switched to the sched_other_rr class.
  */
 static void switched_to_other_rr(struct rq *rq, struct task_struct *p,
-			     int running)
+        int running)
 {
-	/*
-	 * Kick off the schedule if running, otherwise just see
-	 * if we can still preempt the current task.
-	 */
-	if (running)
-		resched_task(rq->curr);
-	else
-		check_preempt_curr(rq, p, 0);
+    /*
+     * Kick off the schedule if running, otherwise just see
+     * if we can still preempt the current task.
+     */
+    if (running)
+        resched_task(rq->curr);
+    else
+        check_preempt_curr(rq, p, 0);
 }
 
-static int
+    static int
 select_task_rq_other_rr(struct rq *rq, struct task_struct *p, int sd_flag, int flags)
 {
-	if (sd_flag != SD_BALANCE_WAKE)
-		return smp_processor_id();
+    if (sd_flag != SD_BALANCE_WAKE)
+        return smp_processor_id();
 
-	return task_cpu(p);
+    return task_cpu(p);
 }
 
 const struct sched_class other_rr_sched_class = {
-	.next			= &idle_sched_class,
-	.enqueue_task		= enqueue_task_other_rr,
-	.dequeue_task		= dequeue_task_other_rr,
-	.yield_task		= yield_task_other_rr,
+    .next			= &idle_sched_class,
+    .enqueue_task		= enqueue_task_other_rr,
+    .dequeue_task		= dequeue_task_other_rr,
+    .yield_task		= yield_task_other_rr,
 
-	.check_preempt_curr	= check_preempt_curr_other_rr,
+    .check_preempt_curr	= check_preempt_curr_other_rr,
 
-	.pick_next_task		= pick_next_task_other_rr,
-	.put_prev_task		= put_prev_task_other_rr,
+    .pick_next_task		= pick_next_task_other_rr,
+    .put_prev_task		= put_prev_task_other_rr,
 
 #ifdef CONFIG_SMP
-	.load_balance		= load_balance_other_rr,
-	.move_one_task		= move_one_task_other_rr,
+    .load_balance		= load_balance_other_rr,
+    .move_one_task		= move_one_task_other_rr,
 #endif
 
-	.switched_to  = switched_to_other_rr,
-	.select_task_rq = select_task_rq_other_rr,
+    .switched_to  = switched_to_other_rr,
+    .select_task_rq = select_task_rq_other_rr,
 
-	.set_curr_task          = set_curr_task_other_rr,
-	.task_tick		= (void *)task_tick_other_rr,
+    .set_curr_task          = set_curr_task_other_rr,
+    .task_tick		= (void *)task_tick_other_rr,
 };
